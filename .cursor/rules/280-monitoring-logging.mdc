# Monitoring and Logging Guidelines

This rule defines standards for logging, monitoring, alerting, and tracing across the application.

## Logging Standards

### 1. Log Levels
```python
from enum import Enum
from typing import Any, Dict, Optional
from datetime import datetime
import logging
import json

class LogLevel(Enum):
    """Standard log levels with usage guidelines."""
    DEBUG = logging.DEBUG    # Detailed information for debugging
    INFO = logging.INFO      # General operational events
    WARNING = logging.WARNING  # Unexpected but handled events
    ERROR = logging.ERROR    # Errors that prevent operation
    CRITICAL = logging.CRITICAL  # System is unusable

class LogEntry:
    """Structured log entry format."""
    def __init__(
        self,
        message: str,
        level: LogLevel,
        context: Optional[Dict[str, Any]] = None
    ):
        self.timestamp = datetime.utcnow()
        self.message = message
        self.level = level
        self.context = context or {}
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert log entry to dictionary."""
        return {
            "timestamp": self.timestamp.isoformat(),
            "level": self.level.name,
            "message": self.message,
            "context": self.context
        }
    
    def to_json(self) -> str:
        """Convert log entry to JSON string."""
        return json.dumps(self.to_dict())

# Usage example
log_entry = LogEntry(
    message="User authentication failed",
    level=LogLevel.WARNING,
    context={
        "user_id": "123",
        "ip_address": "192.168.1.1",
        "attempt": 2
    }
)
```

### 2. Logging Configuration
```python
import logging.config

LOGGING_CONFIG = {
    "version": 1,
    "disable_existing_loggers": False,
    "formatters": {
        "json": {
            "()": "pythonjsonlogger.jsonlogger.JsonFormatter",
            "fmt": "%(timestamp)s %(level)s %(name)s %(message)s"
        },
        "standard": {
            "format": "%(asctime)s [%(levelname)s] %(name)s: %(message)s"
        }
    },
    "handlers": {
        "console": {
            "class": "logging.StreamHandler",
            "formatter": "standard",
            "stream": "ext://sys.stdout"
        },
        "file": {
            "class": "logging.handlers.RotatingFileHandler",
            "formatter": "json",
            "filename": "app.log",
            "maxBytes": 10485760,  # 10MB
            "backupCount": 5
        }
    },
    "loggers": {
        "app": {
            "level": "INFO",
            "handlers": ["console", "file"],
            "propagate": False
        }
    }
}
```

## Monitoring Metrics

### 1. Core Metrics
```python
from dataclasses import dataclass
from typing import List, Dict
from datetime import datetime, timedelta
import prometheus_client as prom

@dataclass
class MetricDefinition:
    """Definition of a monitoring metric."""
    name: str
    type: str  # counter, gauge, histogram, summary
    description: str
    labels: List[str]
    buckets: Optional[List[float]] = None  # For histograms

# Application metrics
REQUEST_LATENCY = MetricDefinition(
    name="http_request_latency_seconds",
    type="histogram",
    description="HTTP request latency in seconds",
    labels=["method", "endpoint", "status"],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
)

ERROR_COUNT = MetricDefinition(
    name="application_errors_total",
    type="counter",
    description="Total number of application errors",
    labels=["type", "component"]
)

ACTIVE_USERS = MetricDefinition(
    name="active_users_count",
    type="gauge",
    description="Number of currently active users",
    labels=["user_type"]
)

# Metric implementation
class MetricsManager:
    """Manage application metrics."""
    
    def __init__(self):
        self.metrics = {}
        
    def create_metric(
        self,
        definition: MetricDefinition
    ) -> None:
        """Create a new metric based on definition."""
        if definition.type == "counter":
            self.metrics[definition.name] = \
                prom.Counter(
                    definition.name,
                    definition.description,
                    definition.labels
                )
        elif definition.type == "gauge":
            self.metrics[definition.name] = \
                prom.Gauge(
                    definition.name,
                    definition.description,
                    definition.labels
                )
        elif definition.type == "histogram":
            self.metrics[definition.name] = \
                prom.Histogram(
                    definition.name,
                    definition.description,
                    definition.labels,
                    buckets=definition.buckets
                )
```

### 2. Custom Business Metrics
```python
# Job-related metrics
JOB_PROCESSING_TIME = MetricDefinition(
    name="job_processing_seconds",
    type="histogram",
    description="Time taken to process jobs",
    labels=["job_type", "status"],
    buckets=[1, 5, 10, 30, 60, 300]
)

JOB_STATUS = MetricDefinition(
    name="job_status_count",
    type="gauge",
    description="Number of jobs by status",
    labels=["status"]
)

# Integration metrics
INTEGRATION_LATENCY = MetricDefinition(
    name="integration_request_latency_seconds",
    type="histogram",
    description="External integration request latency",
    labels=["service", "endpoint"],
    buckets=[0.1, 0.5, 1.0, 5.0, 10.0]
)

INTEGRATION_ERRORS = MetricDefinition(
    name="integration_errors_total",
    type="counter",
    description="Total integration errors",
    labels=["service", "error_type"]
)
```

## Alert Thresholds

### 1. Alert Rules
```python
from dataclasses import dataclass
from typing import Any, Callable
from datetime import timedelta

@dataclass
class AlertRule:
    """Definition of an alert rule."""
    name: str
    description: str
    metric: str
    condition: Callable[[Any], bool]
    threshold: Any
    duration: timedelta
    severity: str
    runbook_url: str

# Example alert rules
class AlertRules:
    """Collection of alert rules."""
    
    @staticmethod
    def high_error_rate() -> AlertRule:
        """Alert on high error rate."""
        return AlertRule(
            name="HighErrorRate",
            description="Error rate exceeds threshold",
            metric="application_errors_total",
            condition=lambda x: x > 10,
            threshold=10,
            duration=timedelta(minutes=5),
            severity="critical",
            runbook_url="/runbooks/high-error-rate"
        )
    
    @staticmethod
    def high_latency() -> AlertRule:
        """Alert on high latency."""
        return AlertRule(
            name="HighLatency",
            description="Request latency exceeds threshold",
            metric="http_request_latency_seconds",
            condition=lambda x: x > 1.0,
            threshold=1.0,
            duration=timedelta(minutes=5),
            severity="warning",
            runbook_url="/runbooks/high-latency"
        )
```

### 2. Alert Configuration
```yaml
# Prometheus alert rules
groups:
  - name: application
    rules:
      - alert: HighErrorRate
        expr: rate(application_errors_total[5m]) > 10
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: High error rate detected
          description: Error rate exceeds 10 errors per minute
          runbook_url: /runbooks/high-error-rate

      - alert: HighLatency
        expr: http_request_latency_seconds > 1.0
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: High latency detected
          description: Request latency exceeds 1 second
          runbook_url: /runbooks/high-latency
```

## Tracing Configuration

### 1. Trace Context
```python
from dataclasses import dataclass
from typing import Optional, Dict
import uuid

@dataclass
class TraceContext:
    """OpenTelemetry-compatible trace context."""
    trace_id: str
    span_id: str
    parent_id: Optional[str]
    sampled: bool
    baggage: Dict[str, str]
    
    @classmethod
    def create_root(cls) -> 'TraceContext':
        """Create a root trace context."""
        return cls(
            trace_id=str(uuid.uuid4()),
            span_id=str(uuid.uuid4())[:16],
            parent_id=None,
            sampled=True,
            baggage={}
        )
    
    def create_child(self) -> 'TraceContext':
        """Create a child trace context."""
        return TraceContext(
            trace_id=self.trace_id,
            span_id=str(uuid.uuid4())[:16],
            parent_id=self.span_id,
            sampled=self.sampled,
            baggage=self.baggage.copy()
        )
```

### 2. Trace Implementation
```python
from typing import Generator
from contextlib import contextmanager
import time

class Tracer:
    """Application tracer implementation."""
    
    def __init__(self):
        self.current_context = None
    
    @contextmanager
    def start_span(
        self,
        name: str,
        context: Optional[TraceContext] = None
    ) -> Generator[TraceContext, None, None]:
        """Start a new trace span."""
        if context is None:
            context = TraceContext.create_root()
        elif self.current_context:
            context = self.current_context.create_child()
        
        start_time = time.time()
        self.current_context = context
        
        try:
            yield context
        finally:
            duration = time.time() - start_time
            # Export span data
            self._export_span(name, context, duration)
            self.current_context = None
    
    def _export_span(
        self,
        name: str,
        context: TraceContext,
        duration: float
    ) -> None:
        """Export span data to tracing backend."""
        span_data = {
            "name": name,
            "trace_id": context.trace_id,
            "span_id": context.span_id,
            "parent_id": context.parent_id,
            "duration": duration,
            "baggage": context.baggage
        }
        # Send to tracing backend (e.g., Jaeger)
```

## Health Checks

### 1. Health Check Implementation
```python
from enum import Enum
from typing import Dict, List, Optional
from dataclasses import dataclass
import aiohttp
import asyncio

class HealthStatus(Enum):
    """Health check status values."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"

@dataclass
class HealthCheck:
    """Health check definition."""
    name: str
    check_type: str  # db, cache, api, etc.
    endpoint: Optional[str] = None
    timeout: float = 5.0
    
    async def check(self) -> Dict[str, Any]:
        """Perform health check."""
        try:
            if self.check_type == "db":
                return await self._check_database()
            elif self.check_type == "cache":
                return await self._check_cache()
            elif self.check_type == "api":
                return await self._check_api()
            else:
                raise ValueError(f"Unknown check type: {self.check_type}")
        except Exception as e:
            return {
                "status": HealthStatus.UNHEALTHY,
                "error": str(e)
            }
    
    async def _check_api(self) -> Dict[str, Any]:
        """Check external API health."""
        if not self.endpoint:
            raise ValueError("Endpoint required for API check")
        
        async with aiohttp.ClientSession() as session:
            try:
                async with session.get(
                    self.endpoint,
                    timeout=self.timeout
                ) as response:
                    return {
                        "status": HealthStatus.HEALTHY
                        if response.status == 200
                        else HealthStatus.UNHEALTHY,
                        "latency": response.elapsed.total_seconds()
                    }
            except asyncio.TimeoutError:
                return {
                    "status": HealthStatus.UNHEALTHY,
                    "error": "Timeout"
                }

class HealthChecker:
    """Manage application health checks."""
    
    def __init__(self):
        self.checks: List[HealthCheck] = []
    
    def add_check(self, check: HealthCheck) -> None:
        """Add a health check."""
        self.checks.append(check)
    
    async def run_checks(self) -> Dict[str, Any]:
        """Run all health checks."""
        results = {}
        overall_status = HealthStatus.HEALTHY
        
        for check in self.checks:
            result = await check.check()
            results[check.name] = result
            
            if result["status"] == HealthStatus.UNHEALTHY:
                overall_status = HealthStatus.UNHEALTHY
            elif result["status"] == HealthStatus.DEGRADED and \
                 overall_status != HealthStatus.UNHEALTHY:
                overall_status = HealthStatus.DEGRADED
        
        return {
            "status": overall_status,
            "checks": results,
            "timestamp": datetime.utcnow().isoformat()
        }
```

### 2. Health Check Configuration
```python
# Example health checks configuration
HEALTH_CHECKS = [
    HealthCheck(
        name="database",
        check_type="db",
        timeout=3.0
    ),
    HealthCheck(
        name="redis",
        check_type="cache",
        timeout=2.0
    ),
    HealthCheck(
        name="linkedin-api",
        check_type="api",
        endpoint="https://api.linkedin.com/health",
        timeout=5.0
    )
]

# FastAPI health check endpoint
from fastapi import FastAPI, HTTPException
from starlette.status import (
    HTTP_200_OK,
    HTTP_503_SERVICE_UNAVAILABLE
)

app = FastAPI()
health_checker = HealthChecker()

for check in HEALTH_CHECKS:
    health_checker.add_check(check)

@app.get("/health")
async def health_check():
    """Health check endpoint."""
    result = await health_checker.run_checks()
    
    if result["status"] == HealthStatus.UNHEALTHY:
        raise HTTPException(
            status_code=HTTP_503_SERVICE_UNAVAILABLE,
            detail=result
        )
    
    return result
```

## Debugging Procedures

### 1. Debug Mode Configuration
```python
from typing import Optional
import sys
import traceback

class DebugConfig:
    """Debug mode configuration."""
    
    def __init__(
        self,
        enabled: bool = False,
        log_level: LogLevel = LogLevel.DEBUG,
        trace_all: bool = False
    ):
        self.enabled = enabled
        self.log_level = log_level
        self.trace_all = trace_all
        self._setup_logging()
    
    def _setup_logging(self) -> None:
        """Configure logging for debug mode."""
        if self.enabled:
            logging.basicConfig(
                level=self.log_level.value,
                format='%(asctime)s [%(levelname)s] '
                       '%(filename)s:%(lineno)d: %(message)s'
            )
    
    def handle_exception(
        self,
        exc: Exception,
        context: Optional[Dict[str, Any]] = None
    ) -> None:
        """Handle and log exceptions in debug mode."""
        if self.enabled:
            exc_info = sys.exc_info()
            stack_trace = ''.join(
                traceback.format_exception(*exc_info)
            )
            
            log_entry = LogEntry(
                message=f"Exception: {str(exc)}",
                level=LogLevel.ERROR,
                context={
                    "stack_trace": stack_trace,
                    "context": context or {}
                }
            )
            logging.error(log_entry.to_json())
```

### 2. Debug Tools
```python
from typing import Any, Dict, List
import inspect
import time

class DebugTools:
    """Collection of debugging tools."""
    
    @staticmethod
    def inspect_object(
        obj: Any,
        max_depth: int = 3
    ) -> Dict[str, Any]:
        """Inspect object attributes and methods."""
        if max_depth <= 0:
            return str(obj)
        
        result = {
            "type": type(obj).__name__,
            "attributes": {},
            "methods": []
        }
        
        # Inspect attributes
        for attr in dir(obj):
            if not attr.startswith('_'):
                try:
                    value = getattr(obj, attr)
                    if inspect.ismethod(value):
                        result["methods"].append({
                            "name": attr,
                            "signature": str(
                                inspect.signature(value)
                            )
                        })
                    else:
                        result["attributes"][attr] = \
                            DebugTools.inspect_object(
                                value,
                                max_depth - 1
                            ) if max_depth > 1 else str(value)
                except Exception as e:
                    result["attributes"][attr] = \
                        f"Error accessing: {str(e)}"
        
        return result
    
    @staticmethod
    def profile_function(func: Callable) -> Callable:
        """Decorator to profile function execution."""
        def wrapper(*args, **kwargs):
            start_time = time.time()
            start_memory = psutil.Process().memory_info().rss
            
            try:
                result = func(*args, **kwargs)
                return result
            finally:
                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss
                
                profile_data = {
                    "function": func.__name__,
                    "execution_time": end_time - start_time,
                    "memory_usage": end_memory - start_memory,
                    "args": str(args),
                    "kwargs": str(kwargs)
                }
                
                logging.debug(
                    f"Function profile: {json.dumps(profile_data)}"
                )
        
        return wrapper 